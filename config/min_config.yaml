# Minimal config for my_replicator
CONFIG:
  renderer: "RayTracedLighting"
  headless: false
  width: 640
  height: 480

# Image size
WIDTH: 640
HEIGHT: 480

# Camera intrinsics (rough defaults)
F_X: 600
F_Y: 600
pixel_size: 0.005  # mm per pixel

# Camera rotation (Euler degrees)
CAMERA_ROTATION: [0, 0, 0]

# Target objects
#
# Option A (recommended): multiple targets
# Each entry becomes an annotated class in COCO/Detectron2.
#
TARGET_OBJECTS:
  - CLASS_NAME: "cup"
    USD: "/home/aidans03/Documents/Research/Projects/isaac-sim/my_replicator/assets/solo_cup.usdc"
    COUNT: 2
  - CLASS_NAME: "crushed_cup"
    USD: "/home/aidans03/Documents/Research/Projects/isaac-sim/my_replicator/assets/crushed_cup.usdc"
    COUNT: 2
#
# Optional per-target overrides:
#   POS_MIN / POS_MAX: per-target spawn bounds (meters)
#   ROT_MIN / ROT_MAX: per-target rotation bounds (degrees)
#
# Option B (legacy): single target
# CUBE_SCALE: [0.1, 0.1, 0.1]
# CLASS_NAME: "cup"
# OBJECT_USD: "/home/aidans03/Documents/Research/Projects/isaac-sim/my_replicator/assets/solo_cup.usdc"

# If true, strip any semantics authored inside USD child prims so PoseWriter only
# annotates the configured target labels.
TARGET_STRIP_CHILD_SEMANTICS: true

# Dome light textures (optional)
# Set DOME_TEXTURES_BASE to the folder containing HDRI files; list names without extension
USE_DOME_LIGHT: true                    # Will change the lighting of the background
DOME_LIGHT_INTENSITY: 500.0
DOME_TEXTURES_BASE: "/home/aidans03/Documents/Research/Projects/isaac-sim/my_replicator/backgrounds"

# Important for dome lighting stability:
# Replicator recommends RTSubframes > 3 to avoid blank dome textures while randomizing HDRIs.
RT_SUBFRAMES: 4

# If DOME_TEXTURES is omitted/empty, min_replicator.py will auto-discover all
# .hdr/.exr files in DOME_TEXTURES_BASE and randomly sample from them each frame.
# To pin to a curated subset, set DOME_TEXTURES (names without extension).
# DOME_TEXTURES:
#   - university_workshop_4k
#   - christmas_photo_studio_07_4k

# Extra driven lights (sphere key/fill). If your scene looks too bright, either:
#  - lower LIGHTS_SPHERE_INTENSITY_SCALE, OR
#  - set LIGHT_KEY_INTENSITY / LIGHT_FILL_INTENSITY directly.
LIGHTS_SPHERE_INTENSITY_SCALE: 0.25      # Will change the lighting of the object
# LIGHT_KEY_INTENSITY: 15000
# LIGHT_FILL_INTENSITY: 8000

# Randomization ranges for object position
# NOTE: The legacy MIN_POSITION/MAX_POSITION was far too large and caused the cup to be off-camera most frames.
# Use the OBJ_* keys instead (read by min_replicator.py).

# Object translation bounds (meters)
# Preferred knobs (per-axis):
OBJ_POS_MIN: [-0.2, -0.2, -0.2]
OBJ_POS_MAX: [0.2, 0.2, 0.2]

# Backward compat (still supported):
OBJ_XY_MIN: [-0.10, -0.10]
OBJ_XY_MAX: [0.10, 0.10]

# Object rotation bounds (degrees)
OBJ_ROT_MIN: [0, 0, 0]
OBJ_ROT_MAX: [0.5, 0.5, 0.5]

# Ground is created at z=0. We spawn the cup so its *bottom* is above the ground.
# If your USD's origin is already at the bottom, set CUP_HEIGHT_M to 0.0.
USE_GROUND_PLANE: false
GROUND_PLANE_SCALE: [10.0, 10.0, 1.0]
GROUND_Z: 0.0
CUP_HEIGHT_M: 0.12

# Optional: keep these unset unless you really want to override the safer OBJ_* ranges.
# MIN_POSITION: [-5.0, -5.0, -5.0]
# MAX_POSITION: [5.0, 5.0, 5.0]

OBJECT_SCALE: [1.0, 1.0, 1.0]

# Distractors (visual noise; NOT annotated)
#
# Isaac Sim built-in assets are referenced via a virtual path (e.g. /Isaac/Props/...).
# Like the official `pose_generation.py`, we resolve these against the Isaac assets root.
DISTRACTOR_COUNT: 50

# Option A (recommended): official-style
DISTRACTOR_ASSET_PATH: /Isaac/Props/YCB/Axis_Aligned/

# If DISTRACTOR_FILENAMES is omitted or empty, min_replicator.py will auto-discover
# all .usd/.usda/.usdc files in DISTRACTOR_ASSET_PATH and sample from them.
# To pin to a curated subset, set DISTRACTOR_FILENAMES to a non-empty list.
# DISTRACTOR_FILENAMES:
#   - 002_master_chef_can
#   - 004_sugar_box

# Option B: explicit full USD paths (uncomment to use)
# DISTRACTOR_USDS:
#   - /Isaac/Props/YCB/Axis_Aligned/002_master_chef_can.usd
#   - /Isaac/Props/YCB/Axis_Aligned/004_sugar_box.usd

# Option C: local filesystem folder scan (only works for real directories)
# DISTRACTOR_DIR: "/home/aidans03/Documents/Research/Projects/isaac-sim/my_replicator/assets"

# Optional pose/scale ranges for the distractors
# (By default the script places them near the target object.)
DISTRACTOR_POS_MIN: [-0.7, -0.7, 0.0]
DISTRACTOR_POS_MAX: [0.7, 0.7, 0.8]
DISTRACTOR_SCALE_MIN: [0.8, 0.8, 0.8]
DISTRACTOR_SCALE_MAX: [1.2, 1.2, 1.2]
DISTRACTOR_ROT_MIN: [0, 0, -180]
DISTRACTOR_ROT_MAX: [0, 0, 180]

# Camera randomization
# Preferred knobs (per-axis):
CAM_POS_MIN: [-1,-1, -1]
CAM_POS_MAX: [1,1,1]

# By default we keep the camera pointed at the object (recommended).
CAM_USE_LOOK_AT: true

# If true, the camera always looks at the sampled object position.
# If false, the look target is sampled independently (using the bounds below).
CAM_USE_OBJECT_POS_AS_LOOK_AT: true

# When multiple targets exist, camera can look at:
#   first  -> always the first target
#   random -> randomly choose one target each frame
CAM_LOOK_AT_TARGET_MODE: first

# Optional: jitter the look_at target around the object (meters)
CAM_LOOK_AT_OFFSET_MIN: [0.0, 0.0, 0.0]
CAM_LOOK_AT_OFFSET_MAX: [0.05, 0.05, 0.05]

# If you set CAM_USE_LOOK_AT: false, these bounds are used instead (degrees)
CAM_ROT_MIN: [0, 0, 0]
CAM_ROT_MAX: [0, 0, 0]

# Backward compat: you can still provide CAM_POSITIONS as a curated list
# CAM_POSITIONS:
#   - [0.00, -1.60, 0.80]
#   - [0.00, -1.20, 0.55]

# Dataset export (post-process PoseWriter outputs)
#
# PoseWriter writes per-frame image + DOPE-style JSON (cuboid keypoints).
# The script can convert those into:
#  - COCO JSON (Detectron2-friendly) and/or
#  - YOLO txt labels (+ a minimal data.yaml)
DATASET_EXPORT: coco          # coco | yolo | both | none
COCO_FILENAME: annotations_coco.json
DATASET_CLASS_MODE: first_token  # first_token | full
DATASET_EXPORT_WAIT_S: 5.0

# COCO/Detectron2 split export
# When enabled, images are reorganized into:
#   <output>/train
#   <output>/validation
#   <output>/test
# and each split gets a single COCO JSON at:
#   <split>/annotations.json
DATASET_SPLIT_ENABLE: true
DATASET_SPLIT_TRAIN: 0.80
DATASET_SPLIT_VALIDATION: 0.10
DATASET_SPLIT_TEST: 0.10
DATASET_SPLIT_COCO_FILENAME: annotations.json

# If true, remove PoseWriter per-frame DOPE JSONs after COCO export.
# (These per-image JSONs are not COCO and can confuse training pipelines.)
DATASET_SPLIT_CLEANUP_FRAME_JSON: true

# If true, also write a root-level COCO file next to the original outputs.
DATASET_SPLIT_WRITE_ROOT_COCO: false

# Optional filters:
# If omitted, it defaults to [CLASS_NAME].
# DATASET_INCLUDE_CLASSES: ["cube"]
# DATASET_EXCLUDE_CLASSES: []

# YOLO output layout is written under: <output>/<YOLO_DIRNAME>/
YOLO_DIRNAME: yolo
YOLO_USE_SYMLINKS: true
